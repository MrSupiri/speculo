{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speculo-FingerPrinter.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_s3w8lcvMqy",
        "colab_type": "code",
        "outputId": "5b3b4b5a-8f60-40f3-c009-d87ead90d10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSWBFCbFx9Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf \"/content/drive/My Drive/Colab Notebooks/Speculo/processed.tar.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwIulFIU0PPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "604d010a-c6b3-451a-a922-bb47e6b8706c"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, \\\n",
        "    MaxPooling2D, BatchNormalization, Flatten, Reshape, Activation, Dropout\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "class Speculo:\n",
        "    def __init__(self):\n",
        "        self.image_size = (64, 64, 1)\n",
        "        self.optimizer = 'adam'\n",
        "        self.loss_function = 'mse'\n",
        "        self.input_img = Input(shape=self.image_size, name=\"input\")\n",
        "        self.filters = (128, 256, 512)\n",
        "        self.latent_size = 256\n",
        "\n",
        "        model_number = 8\n",
        "        if os.path.isdir(\"logs\"):\n",
        "            model_number += len(os.listdir(\"logs/\")) + 1\n",
        "        self.name = f\"v{model_number}-{self.optimizer}-{self.loss_function}-bw\"\n",
        "\n",
        "        self.model = None\n",
        "\n",
        "    def _build_model(self):\n",
        "        chan_dim = -1\n",
        "\n",
        "        x = self.input_img\n",
        "\n",
        "        for f in self.filters:\n",
        "            x = Conv2D(f, (3, 3), activation='relu', padding='same')(x)\n",
        "            x = MaxPooling2D((2, 2))(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "\n",
        "        volume_size = K.int_shape(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Dense(self.latent_size, name=\"latent_space\")(x)\n",
        "\n",
        "        x = Dense(np.prod(volume_size[1:]))(x)\n",
        "        x = Reshape((volume_size[1], volume_size[2], volume_size[3]))(x)\n",
        "\n",
        "        for f in self.filters[::-1]:\n",
        "            x = Conv2DTranspose(f,(3, 3), strides=2, activation='relu', padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "\n",
        "        x = Conv2DTranspose(self.image_size[2], (3, 3), activation='relu', padding='same')(x)\n",
        "        output = Activation(\"sigmoid\", name=\"output\")(x)\n",
        "        \n",
        "        return Model(inputs=self.input_img, outputs=output)\n",
        "\n",
        "    def autoencoder(self):\n",
        "        autoencoder = self._build_model()\n",
        "        # autoencoder.build(self.input_img)\n",
        "        autoencoder.compile(optimizer=self.optimizer, loss=self.loss_function, metrics=['accuracy'])\n",
        "        return autoencoder\n",
        "\n",
        "    def _load_image_set(self, directory, noise_factors=None):\n",
        "        x = []\n",
        "        y = []\n",
        "        fronts = sorted(os.listdir(f\"processed/{directory}/Front/\"))\n",
        "        for i, person_dir in enumerate(sorted(os.listdir(f\"processed/{directory}\"))):\n",
        "            if person_dir == \"Front\":\n",
        "                continue\n",
        "            else:\n",
        "                y_image = Image.open(f\"processed/{directory}/Front/{fronts[i - 1]}\")\n",
        "                y_image = y_image.resize(self.image_size[:2], Image.ANTIALIAS)\n",
        "                if self.image_size[2] == 1:\n",
        "                    y_image = y_image.convert('L')\n",
        "                for image in os.listdir(f\"processed/{directory}/{person_dir}\"):\n",
        "                    x_image = Image.open(f\"processed/{directory}/{person_dir}/{image}\")\n",
        "                    x_image = x_image.resize(self.image_size[:2], Image.ANTIALIAS)\n",
        "                    if self.image_size[2] == 1:\n",
        "                        x_image = x_image.convert('L')\n",
        "                    x.append(np.array(x_image))\n",
        "                    y.append(np.array(y_image))\n",
        "\n",
        "        x = np.array(x).astype(\"float32\") / 255.0\n",
        "        y = np.array(y).astype(\"float32\") / 255.0\n",
        "        x = x.reshape([-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
        "        y = y.reshape([-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
        "\n",
        "        if noise_factors:\n",
        "            noisy_x = []\n",
        "            noisy_y = []\n",
        "            for noise_factor in noise_factors:\n",
        "                noisy_x.append(x + (noise_factor / 10) * np.random.normal(loc=0.0, scale=1.0, size=x.shape))\n",
        "                noisy_y.append(y)\n",
        "            noisy_x = np.reshape(noisy_x, [-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
        "            noisy_y = np.reshape(noisy_y, [-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
        "            return shuffle(np.clip(noisy_x, 0., 1.), noisy_y)\n",
        "        return shuffle(x, y)\n",
        "\n",
        "    def _create_dataset(self):\n",
        "        x_train, y_train = self._load_image_set(\"train\", noise_factors=(0.3, 0.6, 0.9, 1))\n",
        "        x_test, y_test = self._load_image_set(\"test\", noise_factors=(0.3, 0.6))\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "    def _load_model(self):\n",
        "        self.model = load_model(\"models/v8-adam-mse-bw.h5\")\n",
        "        return self.model\n",
        "\n",
        "    def _get_latent_space(self):\n",
        "        autoencoder = self._load_model()\n",
        "        print(autoencoder.layers)\n",
        "        encoder = Model(autoencoder.input,\n",
        "                        autoencoder.get_layer(\"encoder\").input)\n",
        "        # encoder = K.function([autoencoder.input, K.learning_phase()], [autoencoder.get_layer(\"encoder\").output])\n",
        "        # m = Sequential()\n",
        "        # for layer in autoencoder.layers[42:69]:\n",
        "        #     m.add(layer)\n",
        "        # m.build()\n",
        "        return encoder\n",
        "\n",
        "    def predict(self, image):\n",
        "        autoencoder = self._load_model()\n",
        "        output = autoencoder.predict(np.reshape(image, [1, self.image_size[0], self.image_size[1], self.image_size[2]]))\n",
        "        output = (output * 255).astype(\"uint8\")\n",
        "        return np.reshape(output, self.image_size)\n",
        "\n",
        "    def train(self):\n",
        "        x_train, y_train, x_test, y_test = self._create_dataset()\n",
        "        model = self.autoencoder()\n",
        "\n",
        "        checkpoint = ModelCheckpoint(f\"models/{self.name}.h5\", monitor='loss', verbose=1, save_best_only=True,\n",
        "                                     mode='min')\n",
        "        tensorboard = TensorBoard(log_dir=f'logs/{self.name}', histogram_freq=0, write_graph=False)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "        model.fit(x_train, y_train,\n",
        "                  epochs=100,\n",
        "                  batch_size=128,\n",
        "                  shuffle=True,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[checkpoint, tensorboard, early_stopping])\n",
        "\n",
        "        model.save(f\"models/{self.name}.h5\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E28VQUP0xjQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bae269a1-41f5-4f1e-8a91-e278c1551433"
      },
      "source": [
        "speculo = Speculo()\n",
        "print(speculo.autoencoder().summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 64, 64, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 64, 64, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "latent_space (Dense)         (None, 256)               8388864   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32768)             8421376   \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 1)         1153      \n",
            "_________________________________________________________________\n",
            "output (Activation)          (None, 64, 64, 1)         0         \n",
            "=================================================================\n",
            "Total params: 22,126,337\n",
            "Trainable params: 22,124,545\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJSjGZJf3GXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d4d3bab-2a40-4a13-9585-e4f265118297"
      },
      "source": [
        "speculo.train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9992 samples, validate on 552 samples\n",
            "Epoch 1/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 2.1284e-04\n",
            "Epoch 00001: loss improved from inf to 0.03704, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 17s 2ms/sample - loss: 0.0370 - accuracy: 2.1301e-04 - val_loss: 0.0327 - val_accuracy: 2.4768e-05\n",
            "Epoch 2/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 2.3935e-04\n",
            "Epoch 00002: loss improved from 0.03704 to 0.03287, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0329 - accuracy: 2.3916e-04 - val_loss: 0.0625 - val_accuracy: 3.1844e-05\n",
            "Epoch 3/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 2.4172e-04\n",
            "Epoch 00003: loss improved from 0.03287 to 0.03257, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0326 - accuracy: 2.4153e-04 - val_loss: 0.0319 - val_accuracy: 2.7422e-05\n",
            "Epoch 4/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 2.4028e-04\n",
            "Epoch 00004: loss improved from 0.03257 to 0.03210, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0321 - accuracy: 2.4079e-04 - val_loss: 0.0316 - val_accuracy: 2.8306e-05\n",
            "Epoch 5/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 2.4309e-04\n",
            "Epoch 00005: loss improved from 0.03210 to 0.03153, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0315 - accuracy: 2.4289e-04 - val_loss: 0.0310 - val_accuracy: 3.1844e-05\n",
            "Epoch 6/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 2.4478e-04\n",
            "Epoch 00006: loss improved from 0.03153 to 0.03103, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0310 - accuracy: 2.4458e-04 - val_loss: 0.0315 - val_accuracy: 2.9633e-05\n",
            "Epoch 7/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 2.4353e-04\n",
            "Epoch 00007: loss did not improve from 0.03103\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0313 - accuracy: 2.4370e-04 - val_loss: 0.0298 - val_accuracy: 3.1844e-05\n",
            "Epoch 8/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 2.4465e-04\n",
            "Epoch 00008: loss improved from 0.03103 to 0.02984, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0298 - accuracy: 2.4482e-04 - val_loss: 0.0349 - val_accuracy: 3.1844e-05\n",
            "Epoch 9/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 2.4500e-04\n",
            "Epoch 00009: loss improved from 0.02984 to 0.02974, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0297 - accuracy: 2.4480e-04 - val_loss: 0.0294 - val_accuracy: 3.1844e-05\n",
            "Epoch 10/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 2.4500e-04\n",
            "Epoch 00010: loss improved from 0.02974 to 0.02933, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0293 - accuracy: 2.4480e-04 - val_loss: 0.0292 - val_accuracy: 3.1844e-05\n",
            "Epoch 11/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 2.4465e-04\n",
            "Epoch 00011: loss improved from 0.02933 to 0.02895, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0289 - accuracy: 2.4482e-04 - val_loss: 0.0290 - val_accuracy: 3.1844e-05\n",
            "Epoch 12/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 2.4465e-04\n",
            "Epoch 00012: loss improved from 0.02895 to 0.02882, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0288 - accuracy: 2.4482e-04 - val_loss: 0.0292 - val_accuracy: 3.1844e-05\n",
            "Epoch 13/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 2.4502e-04\n",
            "Epoch 00013: loss improved from 0.02882 to 0.02864, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0286 - accuracy: 2.4482e-04 - val_loss: 0.0295 - val_accuracy: 3.1844e-05\n",
            "Epoch 14/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 2.4485e-04\n",
            "Epoch 00014: loss did not improve from 0.02864\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0294 - accuracy: 2.4465e-04 - val_loss: 0.0293 - val_accuracy: 3.0960e-05\n",
            "Epoch 15/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 2.4502e-04\n",
            "Epoch 00015: loss did not improve from 0.02864\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0288 - accuracy: 2.4482e-04 - val_loss: 0.0291 - val_accuracy: 3.1844e-05\n",
            "Epoch 16/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 2.4500e-04\n",
            "Epoch 00016: loss improved from 0.02864 to 0.02857, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0286 - accuracy: 2.4480e-04 - val_loss: 0.0288 - val_accuracy: 3.1402e-05\n",
            "Epoch 17/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 2.4502e-04\n",
            "Epoch 00017: loss improved from 0.02857 to 0.02811, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0281 - accuracy: 2.4482e-04 - val_loss: 0.0289 - val_accuracy: 3.1844e-05\n",
            "Epoch 18/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 2.4502e-04\n",
            "Epoch 00018: loss improved from 0.02811 to 0.02808, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0281 - accuracy: 2.4482e-04 - val_loss: 0.0288 - val_accuracy: 3.1844e-05\n",
            "Epoch 19/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 2.4502e-04\n",
            "Epoch 00019: loss improved from 0.02808 to 0.02795, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0280 - accuracy: 2.4482e-04 - val_loss: 0.0288 - val_accuracy: 3.1844e-05\n",
            "Epoch 20/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 2.4465e-04\n",
            "Epoch 00020: loss improved from 0.02795 to 0.02794, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0279 - accuracy: 2.4482e-04 - val_loss: 0.0286 - val_accuracy: 3.1844e-05\n",
            "Epoch 21/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 2.4500e-04\n",
            "Epoch 00021: loss improved from 0.02794 to 0.02774, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0277 - accuracy: 2.4480e-04 - val_loss: 0.0285 - val_accuracy: 3.1844e-05\n",
            "Epoch 22/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 2.4502e-04\n",
            "Epoch 00022: loss improved from 0.02774 to 0.02760, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0276 - accuracy: 2.4482e-04 - val_loss: 0.0286 - val_accuracy: 3.1844e-05\n",
            "Epoch 23/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 2.4502e-04\n",
            "Epoch 00023: loss improved from 0.02760 to 0.02747, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0275 - accuracy: 2.4482e-04 - val_loss: 0.0292 - val_accuracy: 2.9191e-05\n",
            "Epoch 24/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 2.4502e-04\n",
            "Epoch 00024: loss did not improve from 0.02747\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0282 - accuracy: 2.4482e-04 - val_loss: 0.0284 - val_accuracy: 3.1844e-05\n",
            "Epoch 25/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 2.4502e-04\n",
            "Epoch 00025: loss did not improve from 0.02747\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0277 - accuracy: 2.4482e-04 - val_loss: 0.0285 - val_accuracy: 3.1844e-05\n",
            "Epoch 26/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 2.4465e-04\n",
            "Epoch 00026: loss improved from 0.02747 to 0.02745, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0274 - accuracy: 2.4482e-04 - val_loss: 0.0284 - val_accuracy: 3.4056e-05\n",
            "Epoch 27/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 2.4502e-04\n",
            "Epoch 00027: loss improved from 0.02745 to 0.02730, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0273 - accuracy: 2.4482e-04 - val_loss: 0.0283 - val_accuracy: 4.6882e-05\n",
            "Epoch 28/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 2.4502e-04\n",
            "Epoch 00028: loss improved from 0.02730 to 0.02728, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0273 - accuracy: 2.4482e-04 - val_loss: 0.0285 - val_accuracy: 4.7767e-05\n",
            "Epoch 29/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 2.4465e-04\n",
            "Epoch 00029: loss did not improve from 0.02728\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0274 - accuracy: 2.4482e-04 - val_loss: 0.0284 - val_accuracy: 4.7767e-05\n",
            "Epoch 30/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 2.4465e-04\n",
            "Epoch 00030: loss improved from 0.02728 to 0.02717, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0272 - accuracy: 2.4482e-04 - val_loss: 0.0285 - val_accuracy: 4.7767e-05\n",
            "Epoch 31/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 2.4387e-04\n",
            "Epoch 00031: loss did not improve from 0.02717\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0273 - accuracy: 2.4478e-04 - val_loss: 0.0328 - val_accuracy: 4.5998e-05\n",
            "Epoch 32/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 2.4458e-04\n",
            "Epoch 00032: loss did not improve from 0.02717\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0282 - accuracy: 2.4475e-04 - val_loss: 0.0283 - val_accuracy: 4.7767e-05\n",
            "Epoch 33/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 2.4502e-04\n",
            "Epoch 00033: loss did not improve from 0.02717\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0273 - accuracy: 2.4482e-04 - val_loss: 0.0284 - val_accuracy: 4.7767e-05\n",
            "Epoch 34/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 2.4465e-04\n",
            "Epoch 00034: loss did not improve from 0.02717\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0272 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 35/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 2.4502e-04\n",
            "Epoch 00035: loss improved from 0.02717 to 0.02710, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0271 - accuracy: 2.4482e-04 - val_loss: 0.0284 - val_accuracy: 4.7767e-05\n",
            "Epoch 36/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 2.4502e-04\n",
            "Epoch 00036: loss did not improve from 0.02710\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0273 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 37/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 2.4502e-04\n",
            "Epoch 00037: loss improved from 0.02710 to 0.02707, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0271 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 38/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4502e-04\n",
            "Epoch 00038: loss improved from 0.02707 to 0.02703, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 39/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4502e-04\n",
            "Epoch 00039: loss improved from 0.02703 to 0.02701, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 40/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4502e-04\n",
            "Epoch 00040: loss improved from 0.02701 to 0.02701, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 41/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4502e-04\n",
            "Epoch 00041: loss improved from 0.02701 to 0.02697, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 42/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4465e-04\n",
            "Epoch 00042: loss improved from 0.02697 to 0.02696, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0283 - val_accuracy: 4.7767e-05\n",
            "Epoch 43/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4465e-04\n",
            "Epoch 00043: loss improved from 0.02696 to 0.02695, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0283 - val_accuracy: 4.7767e-05\n",
            "Epoch 44/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 2.4502e-04\n",
            "Epoch 00044: loss improved from 0.02695 to 0.02694, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0269 - accuracy: 2.4482e-04 - val_loss: 0.0283 - val_accuracy: 4.7767e-05\n",
            "Epoch 45/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 2.4502e-04\n",
            "Epoch 00045: loss improved from 0.02694 to 0.02693, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0269 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.5998e-05\n",
            "Epoch 46/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4502e-04\n",
            "Epoch 00046: loss did not improve from 0.02693\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0283 - val_accuracy: 4.7767e-05\n",
            "Epoch 47/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 2.4465e-04\n",
            "Epoch 00047: loss did not improve from 0.02693\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0270 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 48/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 2.4502e-04\n",
            "Epoch 00048: loss did not improve from 0.02693\n",
            "9992/9992 [==============================] - 15s 2ms/sample - loss: 0.0269 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 49/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 2.4465e-04\n",
            "Epoch 00049: loss improved from 0.02693 to 0.02692, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0269 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 50/100\n",
            "9984/9992 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 2.4502e-04\n",
            "Epoch 00050: loss improved from 0.02692 to 0.02691, saving model to models/v8-adam-mse-bw.h5\n",
            "9992/9992 [==============================] - 16s 2ms/sample - loss: 0.0269 - accuracy: 2.4482e-04 - val_loss: 0.0282 - val_accuracy: 4.7767e-05\n",
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaczOkvY53O0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "HSWBFCbFx9Ks",
    "outputId": "837e4d0e-5a83-42c6-b329-8f27e6b1d5b7"
   },
   "outputs": [],
   "source": [
    "# !curl https://cdn.iconicto.com/Speculo/fingerprinter/datasets/test_set.tar.gz -o test_set.tar.gz\n",
    "# !curl https://cdn.iconicto.com/Speculo/fingerprinter/datasets/train_set.tar.gz -o train_set.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5CmpPPH2ElK"
   },
   "outputs": [],
   "source": [
    "# !tar -xf test_set.tar.gz\n",
    "# !tar -xf train_set.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3C3YBxZ-59Zf",
    "outputId": "29d83e2d-7346-4055-a106-6a9de979a055"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pickle\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# data = []\n",
    "# if not os.path.isdir(\"dataset_processed\"):\n",
    "#     raise FileNotFoundError(\"fingerprinter/dataset_processed was not found\")\n",
    "# for person in tqdm(os.listdir(\"dataset_processed\")):\n",
    "#     for Y in os.listdir(os.path.join(\"dataset_processed\", person, \"Y\")):\n",
    "#         for X in os.listdir(os.path.join(\"dataset_processed\", person, \"X\")):\n",
    "#             data.append([os.path.join(\"dataset_processed\", person, \"X\", X),\n",
    "#                             os.path.join(\"dataset_processed\", person, \"Y\", Y)])\n",
    "\n",
    "# random.shuffle(data)\n",
    "# if not os.path.isdir(\"dataset\"):\n",
    "#     os.makedirs(\"dataset\")\n",
    "# file = open('dataset/youtube_data_map.pkl', 'wb')\n",
    "# pickle.dump(data, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwIulFIU0PPJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, \\\n",
    "    MaxPooling2D, BatchNormalization, Flatten, Reshape, Activation, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class AutoEncoderProgress(keras.callbacks.Callback):\n",
    "    def __init__(self, model, n_epoch=1):\n",
    "        super().__init__()\n",
    "        self.speculo = model\n",
    "        self.n_epoch = n_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.n_epoch == 0:\n",
    "            self.speculo.evaluate(f'Model Predictions on epoch {epoch}',\n",
    "                                  f'models/{self.speculo.model_number}/img/predictions-epoch-{epoch}.png')\n",
    "\n",
    "\n",
    "class Speculo:\n",
    "    def __init__(self, image_size=(96, 96, 1), model_path=None, visualize=True, batch_size=64):\n",
    "        self.optimizer = 'adam'\n",
    "        self.loss_function = 'mse'\n",
    "        self.LR = 1e-3\n",
    "\n",
    "        self.filters = (128, 256, 512, 256, 128, 64)\n",
    "        self.latent_size = 512\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.model_path = model_path\n",
    "        self.visualize = visualize\n",
    "        self.dataset_size = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches_per_step = 4\n",
    "\n",
    "        model_number = 1\n",
    "        if os.path.isdir(\"models\"):\n",
    "            model_number += len(os.listdir(\"models\"))\n",
    "\n",
    "        self.model_number = f\"{model_number}\"\n",
    "\n",
    "        self.model = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        input_img = Input(shape=self.image_size, name=\"input\")\n",
    "        x = input_img\n",
    "\n",
    "        for f in self.filters:\n",
    "            x = Conv2D(f, (3, 3), activation='relu', padding='same')(x)\n",
    "            x = MaxPooling2D((2, 2))(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "\n",
    "        size = K.int_shape(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(self.latent_size, name=\"latent_space\")(x)\n",
    "\n",
    "        x = Dense(np.prod(size[1:]))(x)\n",
    "        x = Reshape((size[1], size[2], size[3]))(x)\n",
    "\n",
    "        for f in self.filters[::-1]:\n",
    "            x = Conv2DTranspose(f, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "\n",
    "        x = Conv2DTranspose(self.image_size[2], (3, 3), activation='relu', padding='same')(x)\n",
    "        output = Activation(\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "        return Model(inputs=input_img, outputs=output, name=f\"Speculo-v{self.model_number}\")\n",
    "\n",
    "    def autoencoder(self):\n",
    "        autoencoder = self._build_model()\n",
    "        autoencoder.compile(optimizer=self.optimizer, loss=self.loss_function)\n",
    "        return autoencoder\n",
    "\n",
    "    def display_image_array(self, n, *image_sets, figsize=(8, 4), title=None, labels=None, save_dir=None):\n",
    "        plt.figure(figsize=figsize)\n",
    "        if title:\n",
    "            plt.suptitle(title)\n",
    "        i = 1\n",
    "        row = 0\n",
    "        if labels and len(labels) != len(image_sets):\n",
    "            labels = None\n",
    "        for image_set in image_sets:\n",
    "            for x in range(n):\n",
    "                ax = plt.subplot(len(image_sets), n, i)\n",
    "                if x == 0 and labels:\n",
    "                    ax.set_title(labels[row])\n",
    "                if self.image_size[2] == 1:\n",
    "                    plt.imshow(image_set[x].reshape(self.image_size[:2]))\n",
    "                    plt.gray()\n",
    "                else:\n",
    "                    plt.imshow(image_set[x].reshape(self.image_size))\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "                i += 1\n",
    "            row += 1\n",
    "        if save_dir:\n",
    "            plt.savefig(save_dir)\n",
    "        plt.show()\n",
    "\n",
    "    def read_image(self, file):\n",
    "        im = Image.open(file)\n",
    "        im = im.resize(self.image_size[:2], Image.ANTIALIAS)\n",
    "        if self.image_size[2] == 1:\n",
    "            im = im.convert('L')\n",
    "        return np.array(im)\n",
    "\n",
    "    def _load_image_set(self, directory, noise_factors=None):\n",
    "        x, y = [], []\n",
    "        fronts = sorted(os.listdir(f\"dataset/{directory}/Front/\"))\n",
    "        for i, person_dir in enumerate(sorted(os.listdir(f\"dataset/{directory}\"))):\n",
    "            if person_dir == \"Front\":\n",
    "                continue\n",
    "            else:\n",
    "                y_image = self.read_image(f\"dataset/{directory}/Front/{fronts[i - 1]}\")\n",
    "                for image in os.listdir(f\"dataset/{directory}/{person_dir}\"):\n",
    "                    x_image = self.read_image(f\"dataset/{directory}/{person_dir}/{image}\")\n",
    "                    x.append(np.array(x_image))\n",
    "                    y.append(np.array(y_image))\n",
    "\n",
    "        x = np.array(x).astype(\"float32\") / 255.0\n",
    "        y = np.array(y).astype(\"float32\") / 255.0\n",
    "        x = x.reshape([-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "        y = y.reshape([-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "\n",
    "        if noise_factors:\n",
    "            noisy_x, noisy_y = [], []\n",
    "            for noise_factor in noise_factors:\n",
    "                noisy_x.append(x + (noise_factor / 10) * np.random.normal(loc=0.0, scale=1.0, size=x.shape))\n",
    "                noisy_y.append(y)\n",
    "\n",
    "            noisy_x = np.reshape(noisy_x, [-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "            noisy_y = np.reshape(noisy_y, [-1, self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "\n",
    "            return shuffle(np.clip(noisy_x, 0., 1.), noisy_y)\n",
    "\n",
    "        return shuffle(x, y)\n",
    "\n",
    "    def _image_set_generator(self):\n",
    "        if not os.path.isfile(\"dataset/youtube_data_map.pkl\"):\n",
    "            raise FileNotFoundError(\"dataset/youtube_data_map.pkl was not found\")\n",
    "        file = open('dataset/youtube_data_map.pkl', 'rb')\n",
    "        data = pickle.load(file)\n",
    "        self.dataset_size = len(data)\n",
    "        for x, y in data:\n",
    "            x = self.read_image(x).astype(\"float32\") / 255.0\n",
    "            y = self.read_image(y).astype(\"float32\") / 255.0\n",
    "            x = x.reshape([self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "            y = y.reshape([self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "            yield x, y\n",
    "\n",
    "    def _create_dataset(self):\n",
    "        output_shape = tf.TensorShape([self.image_size[0], self.image_size[1], self.image_size[2]])\n",
    "        data_set = tf.data.Dataset.from_generator(self._image_set_generator,\n",
    "                                                  (tf.float32, tf.float32),\n",
    "                                                  (output_shape, output_shape))\n",
    "        samples_x = []\n",
    "        samples_y = []\n",
    "        for sample in data_set.take(10):\n",
    "            x = np.array(sample[0])\n",
    "            y = np.array(sample[1])\n",
    "            samples_x.append(np.reshape((x * 255).astype(\"uint8\"), self.image_size))\n",
    "            samples_y.append(np.reshape((y * 255).astype(\"uint8\"), self.image_size))\n",
    "        data_set = data_set.batch(self.batches_per_step * self.batch_size).repeat()\n",
    "        x_test, y_test = self._load_image_set(\"test\")\n",
    "        if self.visualize:\n",
    "            self.display_image_array(10, samples_x, samples_y, x_test, y_test,\n",
    "                                     title=f\"Dataset ({self.dataset_size})\",\n",
    "                                     labels=[\"x_train\", \"y_train\", \"x_test\", \"y_test\"],\n",
    "                                     save_dir=f'models/{self.model_number}/img/dataset.png')\n",
    "        return data_set, x_test, y_test\n",
    "\n",
    "    def train(self):\n",
    "        if os.path.exists(f\"models/{self.model_number}\"):\n",
    "            raise FileExistsError(f\"models/{self.model_number} already existing\")\n",
    "        os.makedirs(f\"models/{self.model_number}/img\")\n",
    "\n",
    "        data_set, x_test, y_test = self._create_dataset()\n",
    "        self.model = self.autoencoder()\n",
    "\n",
    "        plot_model(self.model, to_file=f'models/{self.model_number}/img/model.png')\n",
    "\n",
    "        with open(f\"models/{self.model_number}/README.md\", \"w\") as f:\n",
    "            f.write(f\"# Model v{self.model_number}\\n\")\n",
    "            f.write(f\"Optimizer - {self.optimizer} (LR - {self.LR}) <br>\\n\")\n",
    "            f.write(f\"Loss Function - {self.loss_function} <br>\\n\")\n",
    "            f.write(f\"Input Shape - {self.image_size} <br>\\n\")\n",
    "            f.write(f\"Filters - {self.filters} <br>\\n\")\n",
    "            f.write(f\"Latent Size - {self.latent_size} <br>\\n\\n\")\n",
    "            if self.visualize:\n",
    "                f.write(\"### Dataset Sample\\n\")\n",
    "                f.write(\"![DataSet](img/dataset.png)\\n\\n\")\n",
    "            f.write(f\"## Model Summary\\n```shell script\\n\")\n",
    "            self.model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(\"![Model](img/model.png)\\n\\n\")\n",
    "            f.write(f\"## Training Log\\n```shell script\\n\\n```\\n\\n\")\n",
    "\n",
    "        checkpoint = ModelCheckpoint(f\"models/{self.model_number}/Model-v{self.model_number}.h5\", monitor='loss',\n",
    "                                     verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "        tensorboard = TensorBoard(log_dir=f'logs/Model-v{self.model_number}', histogram_freq=0, write_graph=False)\n",
    "        auto_encoder_progress = AutoEncoderProgress(self)\n",
    "        history = None\n",
    "        try:\n",
    "            history = self.model.fit(data_set,\n",
    "                                     epochs=self.dataset_size // (self.batches_per_step * self.batch_size),\n",
    "                                     steps_per_epoch=(self.batches_per_step * self.batch_size),\n",
    "                                     validation_data=(x_test, y_test),\n",
    "                                     validation_steps=self.batch_size,\n",
    "                                     use_multiprocessing=True,\n",
    "                                     callbacks=[checkpoint, tensorboard, auto_encoder_progress])\n",
    "            self.model.save(f\"models/{self.model_number}/Model-v{self.model_number}-Final.h5\")\n",
    "        except KeyboardInterrupt:\n",
    "            pass\n",
    "\n",
    "        finally:\n",
    "            if history:\n",
    "                plt.plot(history.history['loss'])\n",
    "                plt.plot(history.history['val_loss'])\n",
    "                plt.title('Model loss')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.legend(['Train', 'Test'], loc='upper left')\n",
    "                plt.savefig(f'models/{self.model_number}/img/loss.png')\n",
    "                plt.show()\n",
    "\n",
    "            with open(f\"models/{self.model_number}/README.md\", \"a\") as f:\n",
    "                if history:\n",
    "                    f.write(\"### Model loss\\n\")\n",
    "                    f.write(\"![loss](img/loss.png)\\n\\n\")\n",
    "                f.write(\"## Predictions \\n\")\n",
    "                f.write(\"![loss](img/predictions.png)\\n\\n\")\n",
    "                f.write(\"## Notes\\n\")\n",
    "\n",
    "            self.evaluate(file=f'models/{self.model_number}/img/predictions.png')\n",
    "\n",
    "    def _load_model(self):\n",
    "        self.model = load_model(self.model_path)\n",
    "        return self.model\n",
    "\n",
    "    def _get_latent_space(self):\n",
    "        autoencoder = self._load_model()\n",
    "        encoder = Model(inputs=autoencoder.input,\n",
    "                        outputs=autoencoder.get_layer(\"latent_space\").output)\n",
    "        self.model = encoder\n",
    "\n",
    "    def evaluate(self, title=\"Model Predictions\", file=None):\n",
    "        if self.model is None:\n",
    "            self._load_model()\n",
    "        gen_image = []\n",
    "        org_image = []\n",
    "        for image in sorted(os.listdir(\"dataset/evaluate\")):\n",
    "            image = self.read_image(os.path.join(\"dataset/evaluate\", image))\n",
    "            org_image.append(image)\n",
    "            gen_image.append(self.predict(image, preview=True))\n",
    "\n",
    "        self.display_image_array(10, org_image[:10], gen_image[:10],org_image[10:], gen_image[10:],\n",
    "                                 title=title, figsize=(8, 4), save_dir=file)\n",
    "\n",
    "    def predict(self, image, preview=False):\n",
    "        if self.model is None:\n",
    "            self._load_model()\n",
    "        output = self.model.predict(np.reshape(image, [1, self.image_size[0], self.image_size[1], self.image_size[2]]))\n",
    "        if preview:\n",
    "            output = (output * 255).astype(\"uint8\")\n",
    "            return np.reshape(output, self.image_size)\n",
    "        return output.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "5E28VQUP0xjQ",
    "outputId": "6f74ad91-2faa-4fc0-cc0a-bc7d9f045d45",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Speculo-v6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 96, 96, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 96, 96, 128)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 12, 12, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 6, 6, 128)         295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 3, 3, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "latent_space (Dense)         (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_43 (Conv2DT (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_44 (Conv2DT (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_45 (Conv2DT (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_46 (Conv2DT (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_47 (Conv2DT (None, 32, 32, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_48 (Conv2DT (None, 64, 64, 128)       295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_49 (Conv2DT (None, 64, 64, 1)         1153      \n",
      "_________________________________________________________________\n",
      "output (Activation)          (None, 64, 64, 1)         0         \n",
      "=================================================================\n",
      "Total params: 6,159,041\n",
      "Trainable params: 6,156,353\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "speculo = Speculo()\n",
    "print(speculo.autoencoder().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "colab_type": "code",
    "id": "jJSjGZJf3GXN",
    "outputId": "74dc22a4-f02a-4073-9a2c-1024858f70f6",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "models/5 already existing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d1831a2e7b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspeculo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4b4bde38bcfb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{self.model_number}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{self.model_number} already existing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"models/{self.model_number}/img\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: models/5 already existing"
     ]
    }
   ],
   "source": [
    "speculo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Speculo-FingerPrinter.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
